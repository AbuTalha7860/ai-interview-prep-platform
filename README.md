🧠 AI-Mock Interview Platform
An AI-powered mock interview platform designed to help students and job seekers excel in technical and HR interviews. Built during March–April 2025, this platform simulates realistic interviews with real-time speech-to-text input, generates dynamic questions using Gemini Flash 1.5 API, and provides personalized feedback. With a sleek, user-friendly interface, it’s perfect for preparing for top company interviews.
✨ Features

🧑‍💻 AI-Powered Interview Questions — Tailored to role, tech stack, and experience level, curated from top company patterns.
🎙️ Speech-to-Text Input — Answer questions verbally using React Hook Speech-to-Text for a realistic interview experience.
💬 Instant Feedback — Personalized feedback generated by Gemini Flash 1.5 API to improve responses.
📊 Dashboard — Review past interviews, responses, and feedback.
🔐 Authentication — Secure user login with Clerk.
🚀 Scalable Backend — Stores user data and sessions using PostgreSQL (Neon) and Drizzle ORM.

📸 Screenshots



Homepage
Interview Screen
Feedback
Dashboard









🛠️ Tech Stack



Category
Tools Used



Frontend
Next.js 15 (App Router), Tailwind CSS, React Hook Speech-to-Text


Backend
Next.js API Routes, Gemini Flash 1.5 API


Database
PostgreSQL (Neon), Drizzle ORM


State Mgmt
React Hooks (useState, useEffect)


Auth
Clerk


Deployment
Vercel


Icons
Lucide


🚀 Getting Started
1. Clone the Repository
git clone https://github.com/AbuTalha7860/ai-mock-interview.git
cd ai-mock-interview

2. Install Dependencies
npm install

3. Set Up Environment Variables
Create a .env file in the root directory and add:
GEMINI_API_KEY=your_gemini_key
DATABASE_URL=your_database_url
CLERK_PUBLISHABLE_KEY=your_clerk_key
CLERK_SECRET_KEY=your_clerk_secret

4. Run the Development Server
npm run dev

Open http://localhost:3000 in your browser to start.
🖥️ Usage

Sign Up/Login: Authenticate securely using Clerk.
Select Role & Tech Stack: Choose your job role and tech stack for tailored questions.
Answer Verbally: Use speech-to-text to respond to AI-generated questions displayed via GeminiAIModal.js.
Receive Feedback: Get instant, AI-driven feedback to refine your answers.
Track Progress: View past sessions and feedback on the dashboard.

⚙️ Optimization

Lazy Loading: Large components (e.g., modals) are lazy-loaded for faster performance.
Serverless APIs: Next.js API routes ensure scalable, efficient backend operations.
Minimal Dependencies: Reduces bundle size for quick load times.

🛡️ Security & Ethics

API Key Security: Gemini API keys are stored in .env and accessed server-side.
Database Security: Secure PostgreSQL (Neon) connections via DATABASE_URL.
Ethical Use: A disclaimer promotes learning over copying, ensuring critical thinking through tailored content.
Privacy: Speech-to-text data is processed locally and stored securely in PostgreSQL.

🔍 Edge Cases & UX

Loading States: Lucide icon spinners and disabled buttons prevent duplicate submissions during API or speech-to-text processing.
API Failures: Fallback UI alerts users if Gemini Flash 1.5 API fails, with structured prompts to minimize irrelevant responses.
Speech-to-Text: Fallback text input available for low audio quality or heavy accents.

🌟 Future Enhancements

Add audio/video interview support.
Enhance feedback accuracy for niche tech stacks.
Implement user progress tracking and analytics.
Support mentor-scheduled live interviews.

⚠️ Limitations

Limited to technical and HR interviews.
Feedback accuracy depends on Gemini Flash 1.5 API, which may vary for specialized domains.
Speech-to-text may require manual input for low-quality audio.

🌍 Deployment
Hosted on Vercel, optimized for Next.js with seamless CI/CD and performance monitoring.
🤝 Contributing

Fork the repository.
Create a feature branch (git checkout -b feature/your-feature).
Commit changes (git commit -m 'Add your feature').
Push to the branch (git push origin feature/your-feature).
Open a pull request.

📜 License
This project is licensed under the MIT License.
📬 Contact
For questions or feedback, reach out via abutalha@example.com or open an issue on GitHub.
